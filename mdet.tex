\documentclass[twocolappendix, appendixfloats, numberedappendix, twocolumn, apj]{openjournal}

\usepackage{graphicx}
\usepackage{latexsym,amssymb}
\usepackage{amsmath,morefloats}
\usepackage[backref,breaklinks,colorlinks,citecolor=blue]{hyperref}
\usepackage{natbib,graphicx,amsmath,subfigure,color,xcolor}
\usepackage{verbatim}
\usepackage{threeparttable}
\usepackage{xspace}

\topmargin-1cm

\newcommand{\ess}[1]{\textcolor{red}{[ESS: \bf #1]}\xspace}
\newcommand{\mrb}[1]{\textcolor{purple}{[MRB: \bf #1]}\xspace}

\newcommand{\mdet}{\textsc{Metadetection}\xspace}

\shorttitle{\mdet with coadding}
\shortauthors{Becker, Sheldon \& Jarvis}

\begin{document}
\title{A Crude Strategy for Implementing Metadetection Shear Measurements in Real Surveys}

\author{Matthew R. Becker}
\affil{High Energy Physics Division, Argonne National Laboratory, Lemont, IL 60439, USA}
\author{Erin S. Sheldon}
\affil{Brookhaven National Laboratory, Bldg 510, Upton, New York 11973, USA}
\author{Michael Jarvis}
\affil{Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA 19104, USA}


\begin{abstract}
\mdet is a promising technique for making weak gravitational lensing measurements in the presence of
object detection and blending. Currently published tests of this algorithm were only done in
highly idealized situations, neglecting the effects of pixel-level artifact masking, image edges,
and image coaddition through world coordinate system transforms. In this work, we develop algorithms
to address each of these effects and demonstrate that \mdet weak lensing shear measurements are
unbiased to better than 0.1\% even in the presence of these effects. Looking forward, this work provides
a baseline set of algorithms that can be implemented in the analysis pipelines of real surveys.
Future challenges remain, especially concerning image background subtraction, the handling of bright stars, and
pixel noise correlations introduced by sensor effects. Ongoing work in the Dark Energy Survey
will provide the first \mdet measurements for precision cosmology and potentially bring yet unknown issues
to light. The ultimate goal of analyzing the full data sets from the next generation of surveys, such as the
Legacy Survey of Space and Time from the Vera C. Rubin Observatory, will require yet more detailed
testing in even more detailed and realistic simulations.
\end{abstract}


\section{Introduction}\label{sec:intro}

\section{Summary}\label{sec:conc}

\section*{Acknowledgments}

ESS is supported by DOE grant DE-AC02-98CH10886, and MRB is supported by DOE
grant DE-AC02-06CH11357.  We gratefully acknowledge the computing resources
provided on Bebop, a high-performance computing cluster operated by the
Laboratory Computing Resource Center at Argonne National Laboratory, and the
RHIC Atlas Computing Facility, operated by Brookhaven National Laboratory.
This work also used resources made available on the Phoenix cluster, a joint
data-intensive computing project between the High Energy Physics Division and
the Computing, Environment, and Life Sciences (CELS) Directorate at Argonne
National Laboratory.

\bibliographystyle{aasjournal}
\bibliography{references}

% \appendix

\end{document}
